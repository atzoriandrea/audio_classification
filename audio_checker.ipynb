{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "from pydub import AudioSegment\n",
    "\n",
    "video = VideoFileClip('/home/andrea/Scrivania/test_video.mp4')\n",
    "audio = video.audio\n",
    "duration = video.duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "chunks = []\n",
    "step = 14716*3\n",
    "half_step = 7358\n",
    "for t in range(int(audio.buffersize/step)):\n",
    "    t1 = t*step\n",
    "    t2 = (t+1)*step\n",
    "    if t2 > audio.buffersize:\n",
    "        chunks.append(audio.reader.buffer[t1:,0])\n",
    "    else:\n",
    "        chunks.append(audio.reader.buffer[t1:t2,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "audio_buf = audio.reader.buffer[:,0]\n",
    "r = audio_buf.shape\n",
    "start = r[0] - 128000\n",
    "audio_buf = audio_buf[start:]\n",
    "data = []\n",
    "data.append(audio_buf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "test_video = tf.data.Dataset.from_tensor_slices(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Padding for files with less than 16000 samples\n",
    "  zero_padding = tf.zeros([128000] - tf.shape(waveform), dtype=tf.float32)\n",
    "\n",
    "  # Concatenate audio with padding so that all audio clips will be of the\n",
    "  # same length\n",
    "  waveform = tf.cast(waveform, tf.float32)\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=128)\n",
    "\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "  return tf.expand_dims(spectrogram, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "spectrogram_ds = test_video.map(get_spectrogram, num_parallel_calls=-1)\n",
    "batch_size = 1\n",
    "test_ds = spectrogram_ds.batch(batch_size)\n",
    "test_ds = test_ds.cache().prefetch(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE:\n",
    "\n",
    "prendere solo l'audio dello spezzone corretto porta comunque a una misclassificazione"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"audio_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-25c0a3891217>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mnewAudio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAudioSegment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchunks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Scrivania/RC_Carta/venv/lib/python3.6/site-packages/pydub/audio_segment.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m    211\u001B[0m             \u001B[0;31m# normal construction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    212\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 213\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbasestring\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbytes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    214\u001B[0m             \u001B[0;32mexcept\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mOSError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m                 \u001B[0md\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mb''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "newAudio = AudioSegment(data=chunks[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}